{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups # newgroups dataset \n",
    "from sklearn.naive_bayes import MultinomialNB # for model \n",
    "\n",
    "# data processing \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newsgroups to download \n",
    "newsgroup_names = ['comp.graphics', 'rec.sport.hockey', 'sci.electronics', 'sci.space']\n",
    "\n",
    "# get data \n",
    "newsgroups = fetch_20newsgroups(categories=newsgroup_names, shuffle=True, random_state=265)\n",
    "newsgroups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert text into numbers that rep each word\n",
    "word_vector = CountVectorizer()\n",
    "word_vector_counts = word_vector.fit_transform(newsgroups.data)\n",
    "\n",
    "# get frequency of each word \n",
    "term_freq_transformer = TfidfTransformer()\n",
    "term_freq = term_freq_transformer.fit_transform(word_vector_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(term_freq, newsgroups.target) # train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fancy formatting, https://stackoverflow.com/questions/8924173/how-do-i-print-bold-text-in-python\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict some fake test documents \n",
    "test_docs = [\n",
    "    'That GPU has amazing performance with a lot of shaders',\n",
    "    'The player had a wicked slap shot',\n",
    "    'I spent all day yesterday soldering banks of capacitors',\n",
    "    'Today I have to solder a bank of capacitors',\n",
    "    'NASA has rovers on Mars']\n",
    "test_counts = word_vector.transform(test_docs)\n",
    "test_term_freq = term_freq_transformer.transform(test_counts)\n",
    "\n",
    "predictions = model.predict(test_term_freq)\n",
    "print(f'{color.BOLD}Predictions:{color.END}')\n",
    "for doc, group in zip(test_docs, predictions):\n",
    "    print(f'\\t{doc} — {color.UNDERLINE}{newsgroups.target_names[group]}{color.END}')\n",
    "\n",
    "probabilities = model.predict_proba(test_term_freq)\n",
    "print(f'\\n{color.BOLD}Probabilities:{color.END}')\n",
    "print(''.join(['{:20}'.format(name) for name in newsgroups.target_names]))\n",
    "for probs in probabilities:\n",
    "    print(''.join(['{:<20.7}'.format(prob) for prob in probs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option #1 - Standard Difficulty\n",
    "\n",
    "As seen below, words that had significant effects on the model's probabilities include GPU, player, capacitors, and NASA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_docs = [\n",
    "    'That had an amazing performance with a lot of shaders', # replaced 'GPU', should make a signifcant difference\n",
    "    'They had a wicked slap shot', # replaced 'player', should make a significant difference\n",
    "    'I spent all day yesterday soldering', # removed 'banks of capacitors', should make a significant difference\n",
    "    'I had to solder a bank of capacitors', # removed 'today', shouldn't make a significant difference \n",
    "    'They have rovers on Mars'] # replaced 'NASA', should make a significant difference\n",
    "\n",
    "new_test_counts = word_vector.transform(new_test_docs)\n",
    "new_test_term_freq = term_freq_transformer.transform(new_test_counts)\n",
    "\n",
    "new_predictions = model.predict(new_test_term_freq)\n",
    "print(f'{color.BOLD}New Predictions:{color.END}')\n",
    "for doc, group in zip(new_test_docs, new_predictions):\n",
    "    print(f'\\t{doc} — {color.UNDERLINE}{newsgroups.target_names[group]}{color.END}')\n",
    "    \n",
    "new_probabilities = model.predict_proba(new_test_term_freq)\n",
    "print(f'\\n{color.BOLD}New Probabilities:{color.END}')\n",
    "print(''.join(['{:20}'.format(name) for name in newsgroups.target_names]))\n",
    "for new_probs in new_probabilities:\n",
    "    print(''.join(['{:<20.7}'.format(new_prob) for new_prob in new_probs]))\n",
    "\n",
    "print(f'\\n{color.BOLD}Probability Differences:{color.END}')\n",
    "print(''.join(['{:20}'.format(name) for name in newsgroups.target_names]))\n",
    "for i in range(len(new_probs)+1):\n",
    "    diff_arr = []\n",
    "    for old_prob, new_prob in zip(probabilities[i], new_probabilities[i]):\n",
    "        diff_arr.append('{:<20.7}'.format(old_prob-new_prob))\n",
    "    print(''.join(diff_arr))\n",
    "\n",
    "confusing_test_doc = [\n",
    "    'The hockey player was awarded the NASA rover on Mars, which is powered by several cutting-edge RTX graphics cards that have many shaders, and was soldered together by scientists'\n",
    "]\n",
    "\n",
    "confusing_test_counts = word_vector.transform(confusing_test_doc)\n",
    "confusing_test_term_freq = term_freq_transformer.transform(confusing_test_counts)\n",
    "\n",
    "confusing_test_probabilities = model.predict_proba(confusing_test_term_freq)\n",
    "print(f'\\n{color.BOLD}Probabilities for confusing document:{color.END}')\n",
    "print(''.join(['{:20}'.format(name) for name in newsgroups.target_names]))\n",
    "print(''.join(['{:<20.7}'.format(confusing_prob) for confusing_prob in confusing_test_probabilities[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Option #2 - Advanced Difficulty\n",
    "\n",
    "The results of the word counts surprised me. Throughout all the categories, including comp.graphics, gpu was never men tioned. The counts for player and nasa aligned with what I predicted, although the count for capacitors in sci.electronics was lower than I thought it would end up being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citation: got help from Huxley \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html\n",
    "category_graphics = ' '.join(fetch_20newsgroups(remove=('headers', 'footers', 'quotes'), categories=['comp.graphics']).data)\n",
    "category_hockey = ' '.join(fetch_20newsgroups(remove=('headers', 'footers', 'quotes'), categories=['rec.sport.hockey']).data)\n",
    "category_electronics = ' '.join(fetch_20newsgroups(remove=('headers', 'footers', 'quotes'), categories=['sci.electronics']).data)\n",
    "category_space = ' '.join(fetch_20newsgroups(remove=('headers', 'footers', 'quotes'), categories=['sci.space']).data)\n",
    "categories = [category_graphics, category_hockey, category_electronics, category_space]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_graphics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_occurances = []\n",
    "player_occurances = []\n",
    "capacitors_occurances = []\n",
    "nasa_occurances = []\n",
    "# https://www.programiz.com/python-programming/methods/string/count\n",
    "for category in categories: \n",
    "    gpu_occurances.append(category.lower().count(\" gpu \"))\n",
    "    player_occurances.append(category.lower().count(\" player \"))\n",
    "    capacitors_occurances.append(category.lower().count(\" capacitors \"))\n",
    "    nasa_occurances.append(category.lower().count(\" nasa \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{color.BOLD}Counts:{color.END}')\n",
    "print(''.join(['{:17}'.format(name) for name in ['word', *newsgroups.target_names]]))\n",
    "print(''.join(['{:<17}'.format(gpu_occurance) for gpu_occurance in ['gpu', *gpu_occurances]]))\n",
    "print(''.join(['{:<17}'.format(player_occurance) for player_occurance in ['player', *player_occurances]]))\n",
    "print(''.join(['{:<17}'.format(capacitors_occurance) for capacitors_occurance in ['capacitors', *capacitors_occurances]]))\n",
    "print(''.join(['{:<17}'.format(nasa_occurance) for nasa_occurance in ['nasa', *nasa_occurances]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
